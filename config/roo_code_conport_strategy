# --- External Strategy References ---
# This section lists external files containing specific strategies or instructions.
# The LLM assistant should read and incorporate these strategies as needed.
external_strategies:
  prompt_caching:
    file_path: "context_portal/prompt_caching_strategy.yml"
    description: "Defines strategies for leveraging prompt caching with different LLM providers."

conport_memory_strategy:
  workspace_id_source: "The agent must obtain the absolute path to the current workspace to use as `workspace_id` for all ConPort tool calls. This might be available as `${workspaceFolder}` or require asking the user."

  initialization: |
    <thinking>
    - **CONPORT INITIALIZATION AND CONTEXT LOADING:**
    - 1. Determine `ACTUAL_WORKSPACE_ID` (as per workspace_id_source).
    - 2. **Check for Existing Database:**
    -    Use `list_files` tool with `path: ACTUAL_WORKSPACE_ID + "/context_portal/"`.
    -    Examine result for `context.db`.
    - 3. **Branch based on DB Existence:**
    </thinking>
    # Agent Action Plan:
    # 1. Determine `ACTUAL_WORKSPACE_ID`.
    # 2. Invoke `list_files` for `ACTUAL_WORKSPACE_ID + "/context_portal/"`.
    # 3. Analyze result:
    #    IF 'context.db' is found:
    #        Proceed to 'load_existing_conport_context' sequence.
    #    ELSE ('context.db' NOT found):
    #        Proceed to 'handle_new_conport_setup' sequence.

  load_existing_conport_context: | # New sequence
    <thinking>
    - Existing ConPort database found. Attempting to load initial contexts.
    - Will check if loaded context appears empty (which might indicate a reset or issue).
    </thinking>
    # Agent Action Plan:
    # 1. Attempt to load initial contexts from ConPort (same as current strategy's step 2):
    #    Invoke `get_product_context`... Store result.
    #    Invoke `get_active_context`... Store result.
    #    Invoke `get_decisions` (limit 5 for a better overview)... Store result.
    #    Invoke `get_progress` (limit 5)... Store result.
    #    Invoke `get_system_patterns` (limit 5)... Store result.
    #    Invoke `get_custom_data` (category: "critical_settings")... Store result.
    #    Invoke `get_custom_data` (category: "ProjectGlossary")... Store result.
    #    Invoke `get_recent_activity_summary` (default params, e.g., last 24h, limit 3 per type) for a quick catch-up. Store result.
    # 2. Analyze loaded context:
    #    IF results from step 1 are NOT empty/minimal:
    #        Set internal status to [CONPORT_ACTIVE].
    #        Inform user: "ConPort memory initialized. Existing contexts and recent activity loaded."
    #        Use `ask_followup_question` with suggestions like "Review recent activity?", "Continue previous task?", "What would you like to work on?".
    #    ELSE (loaded context is empty/minimal despite DB file existing):
    #        Set internal status to [CONPORT_ACTIVE].
    #        Inform user: "ConPort database file found, but it appears to be empty or minimally initialized. You can start by defining Product/Active Context or logging project information."
    #        Use `ask_followup_question` with suggestions like "Define Product Context?", "Log a new decision?".

    # 3. Handle Load Failure (if step 1's `get_*` calls failed):
    #    If any `get_*` calls in step 1 failed unexpectedly, fall back to `if_conport_unavailable_or_init_failed`.

  handle_new_conport_setup: | # New sequence
    <thinking>
    - No existing ConPort database found. Will ask the user about creating one.
    </thinking>
    # Agent Action Plan:
    # 1. Inform user: "No existing ConPort database found at `ACTUAL_WORKSPACE_ID + "/context_portal/context.db"`."
    # 2. Use `ask_followup_question`:
    #    question: "Would you like to initialize a new ConPort database for this workspace? The database will be created automatically when ConPort tools are first used."
    #    suggestions:
    #      - "Yes, initialize a new ConPort database."
    #      - "No, do not use ConPort for this session."
    # 3. Based on user response:
    #    IF "Yes":
    #        Inform user: "Okay, a new ConPort database will be created."
    #        Attempt to bootstrap Product Context from projectBrief.md (this happens only on new setup):
    #        <thinking>
    #        - Need `ACTUAL_WORKSPACE_ID`.
    #        - Will check for projectBrief.md and offer import.
    #        </thinking>
    #        Invoke `list_files` with `path: ACTUAL_WORKSPACE_ID` (non-recursive, just to check root).
    #        Analyze `list_files` result:
    #        IF 'projectBrief.md' is found in the listing:
    #            Invoke `read_file` for `ACTUAL_WORKSPACE_ID + "/projectBrief.md"`.
    #            Use `ask_followup_question`: "Found projectBrief.md in your workspace. As we're setting up ConPort for the first time, would you like to import its content into the Product Context?"
    #            Suggestions: "Yes, import its content now.", "No, skip importing it for now."
    #            IF user confirms "Yes":
    #                (No need to `get_product_context` as DB is new and empty)
    #                Prepare `content` for `update_product_context`. For example: `{"initial_product_brief": "[content from projectBrief.md]"}`.
    #                Invoke `update_product_context` with the prepared content.
    #                Inform user of the import result (success or failure).
    #        ELSE ('projectBrief.md' NOT found):
    #            Use `ask_followup_question`: "`projectBrief.md` was not found in the workspace root. Would you like to define the initial Product Context manually now?"
    #            Suggestions: "Define Product Context manually.", "Skip for now."
    #            (If "Define manually", guide user through `update_product_context`).
    #        Proceed to 'load_existing_conport_context' sequence (which will now load the potentially bootstrapped product context and other empty contexts).
    #    IF "No":
    #        Proceed to `if_conport_unavailable_or_init_failed` (with a message indicating user chose not to initialize).

  if_conport_unavailable_or_init_failed: |
    <thinking>
    - Initial ConPort tool calls failed, server seems unavailable, or user chose not to initialize.
    - I will inform the user that ConPort could not be initialized/used for context management.
    - I will set my status to [CONPORT_INACTIVE].
    - I will proceed with the user's task using only information directly available or from other tools.
    </thinking>
    # Agent Action: Inform user: "ConPort memory will not be used for this session. Status: [CONPORT_INACTIVE]."

  general:
    status_prefix: "Begin EVERY response with either '[CONPORT_ACTIVE]' or '[CONPORT_INACTIVE]'."
    proactive_logging_cue: "Remember to proactively identify opportunities to log or update ConPort based on the conversation (e.g., if user outlines a new plan, consider logging decisions or progress). Confirm with the user before logging."

  conport_updates:
    frequency: "UPDATE CONPORT THROUGHOUT THE CHAT SESSION, WHEN SIGNIFICANT CHANGES OCCUR, OR WHEN EXPLICITLY REQUESTED."
    workspace_id_note: "All ConPort tool calls require the `workspace_id`."

    # --- Context Management Tools ---
    get_product_context:
      trigger: "To understand the overall project goals, features, or architecture at any time."
      action_description: |
        # Agent Action: Invoke `get_product_context` (`{"raw_args_from_fastmcp": {"workspace_id": "..."}}`). Result is a direct dictionary.
    update_product_context:
      trigger: "When the high-level project description, goals, features, or overall architecture changes significantly, as confirmed by the user."
      action_description: |
        <thinking>
        - Product context needs updating.
        - Step 1: (Optional but recommended if unsure of current state) Invoke `get_product_context`.
        - Step 2: Prepare the `content` (for full overwrite) or `patch_content` (partial update) dictionary.
        - To remove a key using `patch_content`, set its value to the special string sentinel `\"__DELETE__\"`.
        - Confirm changes with the user.
        </thinking>
        # Agent Action: Invoke `update_product_context` (`{"raw_args_from_fastmcp": {"workspace_id": "...", "content": {...}}}` or `{"raw_args_from_fastmcp": {"workspace_id": "...", "patch_content": {"key_to_update": "new_value", "key_to_delete": "__DELETE__"}}}`).
    get_active_context:
      # Similar to get_product_context
    update_active_context:
      # Similar to update_product_context, referencing patch_content and __DELETE__

    # --- Decision Tools ---
    log_decision:
      trigger: "When a significant architectural or implementation decision is made and confirmed by the user."
      action_description: |
        # ... (current description is good, ensure it mentions `tags` as optional List[str])
    get_decisions:
      trigger: "To retrieve a list of past decisions, e.g., to review history or find a specific decision."
      action_description: |
        # Agent Action: Invoke `get_decisions` (`{"raw_args_from_fastmcp": {"workspace_id": "...", "limit": N, "tags_filter_include_all": ["tag1"], "tags_filter_include_any": ["tag2"]}}`). Explain optional filters.
    search_decisions_fts:
      trigger: "When searching for decisions by keywords in summary, rationale, details, or tags, and basic `get_decisions` is insufficient."
      action_description: |
        # Agent Action: Invoke `search_decisions_fts` (`{"raw_args_from_fastmcp": {"workspace_id": "...", "query_term": "search keywords", "limit": N}}`).
    delete_decision_by_id:
      trigger: "When user explicitly confirms deletion of a specific decision by its ID."
      action_description: |
        # Agent Action: Invoke `delete_decision_by_id` (`{"raw_args_from_fastmcp": {"workspace_id": "...", "decision_id": ID}}`). Emphasize prior confirmation.

    # --- Progress Tools ---
    log_progress:
      trigger: "When a task begins, its status changes (e.g., TODO, IN_PROGRESS, DONE), or it's completed. Also when a new sub-task is defined."
      action_description: |
        # ... (current description is good). Add note about `linked_item_type` and `linked_item_id` for automatic linking if relevant context item exists.
    get_progress:
      trigger: "To review current task statuses, find pending tasks, or check history of progress."
      action_description: |
        # Agent Action: Invoke `get_progress` (`{"raw_args_from_fastmcp": {"workspace_id": "...", "status_filter": "...", "parent_id_filter": ID, "limit": N}}`).

    # --- System Pattern Tools ---
    log_system_pattern:
      # ... (current description is good, ensure it mentions `tags` as optional List[str])
    get_system_patterns:
      # ... (similar to get_decisions with tag filters)
    delete_system_pattern_by_id:
      # ... (similar to delete_decision_by_id)

    # --- Custom Data Tools ---
    log_custom_data:
      # ... (current description is good, emphasize value is JSON serializable)
    get_custom_data:
      # ... (current description is good)
    delete_custom_data:
      # ... (current description is good)
    search_custom_data_value_fts:
      trigger: "When searching for specific terms within any custom data values, categories, or keys."
      action_description: |
        # Agent Action: Invoke `search_custom_data_value_fts` (`{"raw_args_from_fastmcp": {"workspace_id": "...", "query_term": "...", "category_filter": "...", "limit": N}}`).
    search_project_glossary_fts:
      trigger: "When specifically searching for terms within the 'ProjectGlossary' custom data category."
      action_description: |
        # Agent Action: Invoke `search_project_glossary_fts` (`{"raw_args_from_fastmcp": {"workspace_id": "...", "query_term": "...", "limit": N}}`).

    # --- Linking Tools ---
    link_conport_items:
      trigger: "When a meaningful relationship is identified and confirmed between two existing ConPort items (e.g., a decision is implemented by a system pattern, a progress item tracks a decision)."
      action_description: |
        <thinking>
        - Need to link two items. Identify source type/ID, target type/ID, and relationship.
        - Common relationship_types: 'implements', 'related_to', 'tracks', 'blocks', 'clarifies', 'depends_on'. Propose a suitable one or ask user.
        </thinking>
        # Agent Action: Invoke `link_conport_items` (`{"raw_args_from_fastmcp": {"workspace_id":"...", "source_item_type":"...", "source_item_id":"...", "target_item_type":"...", "target_item_id":"...", "relationship_type":"...", "description":"Optional notes"}}`).
    get_linked_items:
      trigger: "To understand the relationships of a specific ConPort item, or to explore the knowledge graph around an item."
      action_description: |
        # Agent Action: Invoke `get_linked_items` (`{"raw_args_from_fastmcp": {"workspace_id":"...", "item_type":"...", "item_id":"...", "relationship_type_filter":"...", "linked_item_type_filter":"...", "limit":N}}`).

    # --- History Tool ---
    get_item_history:
      trigger: "When needing to review past versions of Product Context or Active Context, or to see when specific changes were made."
      action_description: |
        # Agent Action: Invoke `get_item_history` (`{"raw_args_from_fastmcp": {"workspace_id":"...", "item_type":"product_context" or "active_context", "limit":N, "version":V, "before_timestamp":"ISO_DATETIME", "after_timestamp":"ISO_DATETIME"}}`).

    # --- Batch Logging Tool ---
    batch_log_items:
      trigger: "When the user provides a list of multiple items of the SAME type (e.g., several decisions, multiple new glossary terms) to be logged at once."
      action_description: |
        <thinking>
        - User provided multiple items. Verify they are of the same loggable type.
        - Construct the `items` list, where each element is a dictionary of arguments for the single-item log tool (e.g., for `log_decision`).
        </thinking>
        # Agent Action: Invoke `batch_log_items` (`{"raw_args_from_fastmcp": {"workspace_id":"...", "item_type":"decision", "items": [{"summary":"...", "rationale":"..."}, {"summary":"..."}] }}`).

    # --- Meta Tools ---
    get_recent_activity_summary:
      trigger: "At the start of a new session to catch up, or when the user asks for a summary of recent project activities."
      action_description: |
        # Agent Action: Invoke `get_recent_activity_summary` (`{"raw_args_from_fastmcp": {"workspace_id":"...", "hours_ago":H, "since_timestamp":"ISO_DATETIME", "limit_per_type":N}}`). Explain default if no time args.
    get_conport_schema: # For LLM's internal use or advanced user query
      trigger: "If there's uncertainty about available ConPort tools or their arguments during a session (internal LLM check), or if an advanced user specifically asks for the server's tool schema."
      action_description: |
        # Agent Action: Invoke `get_conport_schema` (`{"raw_args_from_fastmcp": {"workspace_id":"..."}}`). Primarily for internal LLM reference or direct user request.

    # --- Import/Export Tools ---
    export_conport_to_markdown:
      trigger: "When the user requests to export the current ConPort data to markdown files (e.g., for backup, sharing, or version control)."
      action_description: |
        # Agent Action: Invoke `export_conport_to_markdown` (`{"raw_args_from_fastmcp": {"workspace_id":"...", "output_path":"optional/relative/path"}}`). Explain default output path if not provided.
    import_markdown_to_conport:
      trigger: "When the user requests to import ConPort data from a directory of markdown files previously exported by this system."
      action_description: |
        # Agent Action: Invoke `import_markdown_to_conport` (`{"raw_args_from_fastmcp": {"workspace_id":"...", "input_path":"optional/relative/path"}}`). Explain default input path. Warn about potential overwrites or merges if data already exists.

    # (Keep reconfigure_core_guidance as is)
    reconfigure_core_guidance:
      product_active_context: "The internal JSON structure of 'Product Context' and 'Active Context' (the `content` field) is flexible. Work with the user to define and evolve this structure via `update_product_context` and `update_active_context`. The server stores this `content` as a JSON blob."
      decisions_progress_patterns: "The fundamental fields for Decisions, Progress, and System Patterns are fixed by ConPort's tools. For significantly different structures or additional fields, guide the user to create a new custom context category using `log_custom_data` (e.g., category: 'project_milestones_detailed')."

  conport_sync_routine: # Renamed from umb_update_conport
    trigger: "^(Sync ConPort|ConPort Sync)$" # New trigger phrases
    user_acknowledgement_text: "[CONPORT_SYNCING]" # Simplified acknowledgement, implies active
    instructions:
      - "Halt Current Task: Stop current activity."
      - "Acknowledge Command: Send `[CONPORT_SYNCING]` to the user."
      - "Review Chat History: Analyze the complete current chat session for new information, decisions, progress, context changes, clarifications, and potential new relationships between items."
    core_update_process: |
      <thinking>
      - Synchronize ConPort with information from the current chat session.
      - Use appropriate ConPort tools based on identified changes.
      - For `update_product_context` and `update_active_context`, first fetch current content, then merge/update (potentially using `patch_content`), then call the update tool with the *complete new content object* or the patch.
      - All tool calls require the `workspace_id`.
      </thinking>
      # Agent Action Plan (Illustrative - perform as needed based on chat review):
      # 1. Log new decisions (use `log_decision`).
      # 2. Log task progress/status changes (use `log_progress`).
      # 3. Log new system patterns (use `log_system_pattern`).
      # 4. Update Active Context (use `get_active_context` then `update_active_context` with full or patch).
      # 5. Update Product Context if significant changes (use `get_product_context` then `update_product_context` with full or patch).
      # 6. Log new custom context, including ProjectGlossary terms (use `log_custom_data`).
      # 7. Identify and log new relationships between items (use `link_conport_items`).
      # 8. If many items of the same type were discussed, consider `batch_log_items`.
      # 9. After updates, consider a brief `get_recent_activity_summary` to confirm and refresh understanding.
    post_umb_actions:
      - "Inform user: ConPort synchronized with session info."
      - "Resume previous task or await new instructions."

# --- Prompt Caching Strategies by Provider ---
# This file defines prompt caching strategies tailored for different LLM providers.
# An LLM assistant should select the relevant strategy based on its current model/provider.

prompt_caching_strategies:
  enabled: true # Master switch to enable/disable prompt caching strategies

  # --- Core Mandate (Applies to all enabled providers) ---
  core_mandate: |
    Actively seek opportunities to utilize prompt caching when interacting with the target LLM service.
    Primary goals: Reduce token costs and improve response latency.
    Leverage provider-specific caching mechanisms as defined below.
    - Notify user when structuring a prompt for potential caching: [INFO: Structuring prompt for caching]

  # --- Identifying Cacheable Content from ConPort (Applies to all providers) ---
  content_identification:
    description: |
      Criteria for identifying content from ConPort that is suitable for prompt caching.
      This content will form the stable prefix of prompts sent to the LLM.
    priorities:
      - item_type: "product_context"
        description: "Full text is a high-priority candidate if retrieved and relevant, due to size and relative stability."
      - item_type: "system_pattern"
        description: "Detailed descriptions of complex, frequently referenced patterns, especially if lengthy."
      - item_type: "custom_data"
        description: "Values from entries known/hinted to be large (e.g., specs, guides) or flagged with 'cache_hint: true' metadata."
      - item_type: "active_context"
        description: "Consider large, stable text blocks within active context if they will preface multiple queries *within the current task*."

    heuristics:
      min_token_threshold: 750 # Consider content for caching if it exceeds this approximate token count.
      stability_factor: "high" # Prefer content less likely to change rapidly within a short timeframe.

  # --- User-Defined Cache Hints (Applies to all providers) ---
  user_hints:
    description: |
      Users can provide explicit hints within ConPort item metadata to influence prompt caching decisions.
      These hints prioritize content for inclusion in the cacheable prompt prefix.

    retrieval: |
      When retrieving ConPort items that support metadata (e.g., `custom_data`), check the `metadata` field for the key `cache_hint`.
      If the `metadata` field is a JSON object and contains `"cache_hint": true`, consider the content of this item as a high-priority candidate for prompt caching, provided it also meets size and stability heuristics.

    logging_suggestion: |
      When logging or updating ConPort items (especially `custom_data`) that appear to be excellent caching candidates based on their size, stability, or likely reuse, you SHOULD suggest to the user adding a `cache_hint: true` flag to the item's `metadata` field.
      Confirm with the user before applying.
      Example suggestion: "This [Item Type, e.g., technical specification] seems large and stable, making it a good candidate for prompt caching. Would you like me to add `\"cache_hint\": true` to its metadata in ConPort to prioritize it?"

  # --- Strategy Note: Local Load vs. Provider Persistent Cache (Applies to all providers) ---
  strategy_note: |
    Storing cacheable content locally in ConPort and sending it as a prompt prefix at the start of each session avoids AI provider storage fees. However, this incurs the full input token cost for that content in every session and may increase initial latency compared to leveraging the provider's persistent caching with its discounted usage fees. The optimal approach depends on session frequency and content size. Provider-specific strategies below detail how to interact with their caching mechanisms.

  # --- Provider Specific Strategies ---

  gemini_api:
    description: Strategy for Google Gemini models (e.g., 1.5 Pro, 1.5 Flash) which support implicit caching.
    interaction_protocol:
      type: "implicit"
      details: |
        Leverage Gemini's implicit caching by structuring prompts.
        1. Retrieve the stable, cacheable context from ConPort (based on identification rules).
        2. Place this retrieved ConPort text at the *absolute beginning* of the prompt sent to Gemini.
        3. Append any variable, task-specific parts (e.g., user's specific question, code snippets for analysis) *after* the stable prefix.
        Example: "[Retrieved Product Context Text] \n\n Now, answer this specific question: [User's Question]"
    staleness_management:
      details: |
        Be aware that ConPort data can be updated. Cached versions of that data in Gemini have a TTL.
        While direct invalidation isn't typically managed via implicit caching APIs, structuring prompts consistently helps Gemini manage its cache.
        If you know a core piece of ConPort context (like Product Context) has just been updated, the *next* prompt you send using that context *as a prefix* will naturally cause Gemini to process and potentially re-cache the new version.

  anthropic_api:
    description: Strategy for Anthropic Claude models (e.g., 3.5 Sonnet, 3 Haiku, 3 Opus) which require explicit cache control.
    interaction_protocol:
      type: "explicit"
      details: |
        Utilize Anthropic's explicit prompt caching via `cache_control` breakpoints.
        1. Identify cacheable content from ConPort (based on identification rules and user hints).
        2. Construct the prompt message payload for the Anthropic API.
        3. Insert a `cache_control` breakpoint *after* the stable, cacheable content and *before* the variable content.
        Example (Conceptual API payload structure):
        {
          "messages": [
            {"role": "user", "content": "[Stable ConPort Content]"},
            {"role": "user", "content": {"type": "tool_code", "text": "<cache_control>{\"type\": \"set_cache_break\"}</cache_control>"}}, # Example breakpoint syntax
            {"role": "user", "content": "[Variable User Query]"}
          ],
          ...
        }
        (Note: The exact syntax for `cache_control` may vary; refer to Anthropic API docs.)
    staleness_management:
      details: |
        Anthropic's explicit caching may offer more control over invalidation or TTL, but details need confirmation from their API documentation.
        If ConPort data is updated, ensure subsequent prompts use the updated content, which should trigger re-caching or correct handling by the Anthropic API based on its specific rules.

  openai_api:
    description: Strategy for OpenAI models with automatic prompt caching.
    interaction_protocol:
      type: "implicit"
      details: |
        Leverage OpenAI's automatic prompt caching by structuring prompts.
        This is similar to Gemini's implicit caching and requires no explicit markers.
        1. Identify cacheable content from ConPort (based on identification rules and user hints).
        2. Place this retrieved ConPort text at the *absolute beginning* of the prompt sent to the OpenAI API.
        3. Append any variable, task-specific parts *after* the stable prefix.
        OpenAI provides a 50% discount on cached input tokens. Caching automatically activates for prompts over a certain length (e.g., >1024 tokens, but verify current documentation).
    staleness_management:
      details: |
        Automatic caching handles staleness implicitly. If prompt prefix changes (e.g., updated ConPort data), OpenAI processes/re-caches new prefix.

  other_providers:
    description: Placeholder for other LLM providers with prompt caching.
    interaction_protocol:
      type: "unknown" # Research needed
    staleness_management:
      details: "Research required."
